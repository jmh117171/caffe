"""
Created on 18-7-30
@author: minghui_J
"""
#use place365 to classify the picture of weibo
#use weight to confirm which category(6) //map 365 to 6 classes
#!/usr/bin/env python
import numpy as np
import matplotlib.pyplot as plt
import shutil
import ctypes
#%matplotlib inline
plt.rcParams['figure.figsize']=(10,10)
plt.rcParams['image.interpolation']='nearest'
plt.rcParams['image.cmap']='gray'
import sys
caffe_root='/home/jmh/caffe/'
sys.path.insert(0,caffe_root+'python')
import caffe
import os
if os.path.isfile(caffe_root+'models/bvlc_reference_caffenet/vgg16_places365.caffemodel'):
    print 'CaffeNet found.'
else:
    print 'Downloading pre-trained CaffeNet model...'
    #!../scripts/download_model_binary.py ../models/bvlc_reference_caffenet
caffe.set_mode_cpu()
model_def=caffe_root+'models/bvlc_reference_caffenet/deploy_vgg16_places365.prototxt'
model_weights=caffe_root+'models/bvlc_reference_caffenet/vgg16_places365.caffemodel'
net=caffe.Net(model_def,model_weights,caffe.TEST)
#net.forward()
mu = np.load(caffe_root+'python/caffe/imagenet/ilsvrc_2012_mean.npy')
mu = mu.mean(1).mean(1)
print 'mean-subtracted values:',zip('BGR',mu)
transformer = caffe.io.Transformer({'data':net.blobs['data'].data.shape})
transformer.set_transpose('data',(2,0,1))
transformer.set_mean('data',mu)
transformer.set_raw_scale('data',255)
transformer.set_channel_swap('data',(2,1,0))
net.blobs['data'].reshape(1,3,224,224)
result_list=[]
#pic_list=os.listdir('/home/jmh/caffe/data/ilsvrc12')
#pic_file_list=[]
#for pic in pic_list:
#    if '.jpg' in pic:
#        pic_file_list.append(pic)
#for pic in pic_file_list:
#    pic_path=os.path.join('/home/jmh/caffe/data/ilsvrc12',pic)
#    image=caffe.io.load_image(pic_path)
#    transformed_image=transformer.preprocess('data',image)

#image = caffe.io.load_image(caffe_root+'data/ilsvrc12/restaurant/005WVBNyjw1eo4i964355j318g0xcwnh.jpg')
DataR_root='/home/jmh/caffeCode/PicIds1.txt'
DataW_root='/home/jmh/caffeCode/PicIds2.txt'
f=open(DataR_root,'r')
out=open(DataW_root,'w')
lines=f.readlines()
i=0
for line in lines:
    if i<=15:
	pic_ids=[]
        classes={}
        lizt=line.split(' ')
	lizt[5]=lizt[5].strip('[').strip(']').split(',')
	lizt[4]=lizt[4].split('/')
	root='/'.join(lizt[4][:-1])
	for one in lizt[5]:
	    pic_ids.append(root+'/'+one+'.jpg')
	print pic_ids
	for pic_id in pic_ids:
            image = caffe.io.load_image(pic_id)
            transformed_image = transformer.preprocess('data',image)
            plt.imshow(image)
            #plt.show()
            net.blobs['data'].data[...]=transformed_image
            output = net.forward()
            output_prob = output['prob'][0]
            print 'predicted class is:',output_prob.argmax()
            labels_file=caffe_root + 'data/ilsvrc12/category365-6.txt'
            labels = np.loadtxt(labels_file,str,delimiter='\t')
            label_name=labels[output_prob.argmax()].split(' ')[0]
            number=labels[output_prob.argmax()].split(' ')[1]
	    if number not in classes:
		classes[number]=1
	    else:
		classes[number]+=1
            print 'output label:',label_name
            print 'number:',number
	number=max(classes,key=classes.get)
        print number
        out.write(lizt[0]+' '+lizt[1]+' '+lizt[2]+' '+lizt[3]+' '+str(number)+' '+'\n')
    i+=1
f.close()
out.close()
    #label_name_list=label_name.split('/')
    #if(len(label_name_list)>3):
    #    label_name=label_name_list[2]+'-'+label_name_list[3]
    #else:
    #    label_name=label_name_list[2]
    #print label_name
#    newpath=os.path.join('/home/jmh/caffe/data/ilsvrc12/',label_name)
#    if os.path.isdir(newpath):
#        shutil.move(pic_path,newpath)
#    else:
#	os.makedirs(newpath)
#	shutil.move(pic_path,newpath)
#label_name_list=labels_name.split('/')[2]
print 'end******************'
#top_inds = output_prob.argsort()[::-1][:5]
#print 'probailities and labels:\n',zip(output_prob[top_inds],labels[top_inds])
#%timeit net.forward()
#for layer_name,blob in net.blobs.iteritems():
#    print layer_name + '\t' + str(blob.data.shape)
#for layer_name,param in net.params.iteritems():
#    print layer_name +'\t' +str(param[0].data.shape),str(param[1].data.shape)
#def vis_square(data):
#    data=(data-data.min())/(data.max()-data.min())
#    n=int(np.ceil(np.sqrt(data.shape[0])))
#    padding=(((0,n**2-data.shape[0]),(0,1),(0,1))+((0,0),)*(data.ndim-3))
#    data=np.pad(data,padding,mode='constant',constant_values=1)
#    data=data.reshape((n,n)+data.shape[1:]).transpose((0,2,1,3)+tuple(range(4,data.ndim+1)))
#    data=data.reshape((n*data.shape[1],n*data.shape[3])+data.shape[4:])
#    plt.imshow(data);
#filters=net.params['conv1_1'][0].data
#vis_square(filters.transpose(0,2,3,1))
#plt.show()
#feat=net.blobs['data'].data[0,:3]
#vis_square(feat)
#plt.show()
#feat=net.blobs['fc7'].data[0]
#plt.subplot(2,1,1)
#plt.plot(feat.flat)
#plt.subplot(2,1,2)
#a=plt.hist(feat.flat[feat.flat>0],bins=100)
#plt.show()
#feat=net.blobs['prob'].data[0]
#plt.figure(figsize=(15,3))
#plt.plot(feat.flat)
#plt.show()
